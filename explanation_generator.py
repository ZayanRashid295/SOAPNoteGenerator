from typing import Dict

def generate_explanation(soap_notes: Dict[str, str], best_soap_note: str, scores: Dict) -> str:
    explanation_prompt = f"""
    Compare and merge best data for all headings from the following SOAP notes generated by different models:

    SOAP Notes:
    {'-' * 80}
    1. Gemma API:
    {soap_notes['gemma']}
    {'-' * 80}
    2. DeepSeek API:
    {soap_notes['deepseek']}
    {'-' * 80}
    3. Meta Llama API:
    {soap_notes['meta_llama']}
    {'-' * 80}
    4. OpenAI MAI-DS API:
    {soap_notes['microsoft_mai_ds']}
    {'-' * 80}
   
    Merged Best SOAP Note:
    {best_soap_note}

    Scores:
    Completeness: {scores['completeness']}
    Clarity: {scores['clarity']}
    Relevance: {scores['relevance']}
    Total Score: {scores['total']}

    Please provide a detailed analysis explaining:
    1. Why the selected SOAP note is considered the best
    2. Specific strengths and weaknesses of each SOAP note
    3. How the scoring metrics were applied (completeness, clarity, relevance, and total score)
    4. Recommendations for potential improvements for the selected SOAP note
    """
    
    try:
        # Using DeepSeek API for explanation
        response = deepseek_api_call(
            model="deepseek/deepseek-r1:free",
            messages=[{
                "role": "system",
                "content": "You are a medical documentation expert analyzing SOAP notes."
            }, {
                "role": "user",
                "content": explanation_prompt
            }],
            temperature=0.7,
            max_tokens=1000
        )
        explanation = response.choices[0].message.content
        if not explanation.strip():
            raise ValueError("Empty explanation generated.")
        return explanation
    except Exception as e:
        print(f"Error generating explanation with DeepSeek API: {str(e)}")
        # Fallback explanation
        return generate_fallback_analysis(soap_notes, best_soap_note, scores)

def generate_fallback_analysis(soap_notes: Dict[str, str], best_soap_note: str, scores: Dict) -> str:
    """
    Generate a basic fallback analysis if the DeepSeek API fails.
    """
    analysis = "Fallback Analysis:\n\n"
    analysis += "The following SOAP notes were analyzed:\n"
    for api_name, note in soap_notes.items():
        analysis += f"- {api_name.capitalize()} API: {len(note.split())} words\n"

    analysis += "\nThe best SOAP note was selected based on the following scores:\n"
    analysis += f"  Completeness: {scores['completeness']}\n"
    analysis += f"  Clarity: {scores['clarity']}\n"
    analysis += f"  Relevance: {scores['relevance']}\n"
    analysis += f"  Total Score: {scores['total']}\n"

    analysis += "\nStrengths of the selected SOAP note:\n"
    analysis += "- Comprehensive coverage of all SOAP sections.\n"
    analysis += "- Clear and concise language.\n"
    analysis += "- Relevant details included.\n"

    analysis += "\nRecommendations for improvement:\n"
    analysis += "- Ensure more detailed explanations in the 'Assessment' section.\n"
    analysis += "- Add more specific follow-up plans in the 'Plan' section.\n"

    return analysis

# Placeholder for DeepSeek API implementation
def deepseek_api_call(**kwargs):
    """
    This is a placeholder function for the actual DeepSeek API implementation.
    In a real implementation, you would:
    1. Import the DeepSeek API client
    2. Set up authentication
    3. Make the actual API call
    4. Return the response
    
    For now, it returns a simple response for demonstration purposes.
    """
    class MockResponse:
        def __init__(self):
            class Choice:
                def __init__(self):
                    class Message:
                        def __init__(self):
                            self.content = f"DeepSeek Analysis: {kwargs['messages'][1]['content'][:100]}... [FULL ANALYSIS WOULD BE HERE]"
                    self.message = Message()
            self.choices = [Choice()]
    
    return MockResponse()